#' A sampler for estimating the W matrix in a SAR type model
#'
#' The model takes thes form \eqn{Y = \rho WY + X \beta_1 + WX \beta_2 + Z \beta_3 +  \epsilon}, with \eqn{\epsilon \sim N(0,\sigma^2)}
#'
#' @param Y An \eqn{tt n x 1} matrix of dependent variables
#' @param X An \eqn{tt n x q_x} matrix of independent variables
#' @param Z An \eqn{tt n x q_k} matrix of independent variables
#' @param priors List of priors, generated by \code{\link{init_priors}}
#' @param tt Number of time observations
#' @param niter Total number of iterations
#' @param nretain Number of iterations to retain (must be smaller than niter)
#' @param VERBOSE Should detailed diagnostic information be provided (default: FALSE)
#' @param SYMMETRIC Should the estimated \eqn{W} matrix be symmetric (default: TRUE)
#' @param GRIDDY_GIBBS Should griddy-Gibbs be used for \eqn{\rho} estimation?
#' Does not work if \code{ROW_STANDARDIZED = FALSE}. Main advantage is that less draws are required for \eqn{\rho}
#' @param ROW_STANDARDIZED Should the estimated \eqn{W} matrix be row-standardized (default: TRUE)
#'
#' @return List with posterior samples for \eqn{\rho}, \eqn{\beta}, \eqn{\sigma^2}, \eqn{w}, and direct, indirect, and total effects.
#' @export sdmw
#'
#' @examples
#' n = 20; tt = 10
#' dgp_dat = sarwsim(n =n, tt = 10, k=3, rho = .5, beta = c(1,-1,1), sigma2 = .5)
#' res = sdmw(Y = dgp_dat$Y,X = matrix(0,n*tt,0),Z = dgp_dat$X,tt = tt,niter = 20,nretain = 10)
sdmw <- function(Y, X = matrix(0,nrow(Y),0),Z = matrix(0,nrow(Y),0), tt, niter = 1000, nretain = 250,
                  priors = init_priors(X,Z,tt),
                   VERBOSE = FALSE, SYMMETRIC = TRUE, GRIDDY_GIBBS = TRUE, ROW_STANDARDIZED = TRUE) {
  if (ncol(X) == 0 && ncol(Z) == 0) {stop("Error: At least either X or Z matrix have to be provided.")}
  origX = X

  smallk = ncol(X)
  if (smallk>0 && is.null(colnames(X))) {
    colnames(X) = paste0("X",1:smallk)
  }
  k_dum = ncol(Z)
  if (k_dum>0 && is.null(colnames(Z))) {
    colnames(Z) = paste0("Z",1:k_dum)
  }
  if (smallk>0) {varnames = c(colnames(X), paste0("W_",colnames(X)))} else {varnames = c()}
  if (k_dum > 0) varnames = c(varnames,colnames(Z))

  if (!ROW_STANDARDIZED && GRIDDY_GIBBS) {
    stop("No support for Griddy Gibbs without row-standardization!")
  }

  ndiscard <- niter - nretain
  k <- smallk*2 + k_dum
  n <- nrow(X) / tt

  # map variable positions for spatial effects
  ind_baseX = ind_WX = ind_lagFX = c()
  if (smallk > 0) {
    ind_baseX = c(1:smallk)
    # the columns of XX that are spatially lagged
    ind_WX = c(1:smallk) + smallk
    # the spatial FX corresponding to these
    ind_lagFX = 1:smallk
  }
  if (k_dum > 0) {ind_baseX = c(ind_baseX,(2*smallk + 1):k)}

  diag(priors$W_prior) <- 0

  rho_scale <- 1
  rho_accept <- 0

  # save the posterior draws here
  postb <- matrix(0, k, nretain)
  rownames(postb) <- varnames
  posts <- matrix(0, 1, nretain)
  postr <- matrix(0, 1, nretain)
  postw <- array(0, c(n, n, nretain))
  postwprob <- array(0, c(n, n, nretain))

  post.direct <- matrix(0, smallk + k_dum, nretain)
  post.indirect <- matrix(0, smallk + k_dum, nretain)
  post.total <- matrix(0, smallk + k_dum, nretain)
  rownames(post.direct) <- rownames(post.indirect) <- rownames(post.total) <- varnames[ind_baseX]

  # pre-calculate some terms for faster draws
  beta_prior_var_inv <- solve(priors$beta_prior_var)
  curr.W <- matrix(0, n, n) # not standardized W
  ### generate curr.W from the prior distribution
  if (SYMMETRIC) {
    ii_samples <- sample(2:n, n - 1, replace = F)
  } else {
    ii_samples <- sample(1:n, n, replace = F)
  }
  for (i in ii_samples) {
    if (SYMMETRIC) {
      jj_samples <- sample(c(1:(i - 1)), i - 1, replace = F)
    } else {
      jj_samples <- sample(1:n, n, replace = F)
    }
    for (j in jj_samples) {
      curr.Wpr <- priors$W_prior[i, j]
      if (SYMMETRIC) {
        neighb1 <- sum((curr.W + t(curr.W))[i, ])
      } else {
        neighb1 <- sum(curr.W[i, ])
      }
      if (priors$rjct_pr) {
        if (SYMMETRIC) {
          rjct_n <- max(neighb1, sum((curr.W + t(curr.W))[j, ]))
        } else {
          rjct_n <- neighb1
        }
        if (rjct_n < priors$min_k) {
          curr.Wpr <- 1
        } else if (rjct_n == priors$max_k) {
          curr.Wpr <- 0
        }
      }
      if (priors$bb_pr) {
        bbprior1 <- bbinompdf(neighb1, n - 1, priors$bbinom_a, priors$bbinom_b) * curr.Wpr
        bbprior0 <- (1 - bbinompdf(neighb1, n - 1, priors$bbinom_a, priors$bbinom_b)) * (1 - curr.Wpr)
        bbprior_ <- bbprior1 / (bbprior1 + bbprior0)
      } else {
        bbprior_ <- curr.Wpr
      }
      prob.delta <- bbprior_ / (bbprior_ + (1 - bbprior_))
      if (prob.delta == 1) {
        curr.W[i, j] <- 1
      } else if (prob.delta != 0) {
        curr.W[i, j] <- stats::rbinom(1, 1, prob.delta)
      }
    }
  }
  # # set-up random W, so that all have min_k neighbours
  # nr_gen_neighbours = min((min_k + max_k)/2,ceiling(n/10))
  # iter = 1
  # sample_from = 1:n
  # while (any(rowSums(curr.W) < min_k) && iter < n*100) {
  #   nneigh = sample(sample_from,2)
  #   prop.W = curr.W
  #   prop.W[nneigh[1],nneigh[2]] = 1
  #   prop.W[nneigh[2],nneigh[1]] = 1
  #   if ( all(sum(prop.W[nneigh,]) < max_k) ) {
  #     curr.W = prop.W
  #   }
  #   if (any(rowSums(curr.W[sample_from,]) >= min_k) && length(sample_from) > 1) {
  #     sample_from = c(1:n)[-which(rowSums(curr.W)>=min_k)]
  #   }
  #   iter = iter + 1
  # }
  if (SYMMETRIC) {
    curr.W[upper.tri(curr.W, diag = tt)] <- 0
  }
  # curr.w - row-standardized
  curr.w <- matrix(0, n, n)
  if (ROW_STANDARDIZED) {
    if (SYMMETRIC) {
      curr.w <- (curr.W + t(curr.W)) / rowSums((curr.W + t(curr.W)))
    } else {
      curr.w <- curr.W / rowSums(curr.W)
    }
    curr.w[is.na(curr.w)] <- 0
  } else {
    if (SYMMETRIC) {
      curr.w <- curr.W + t(curr.W)
    } else {
      curr.w <- curr.W
    }
  }

  curr.WX = as.matrix(kronecker(Matrix::.sparseDiagonal(tt),curr.w) %*% X)
  tX = cbind(X,curr.WX,Z)
  tY <- matrix(Y, n, tt)
  tAy <- matrix(0, n, tt)
  curr.beta <- solve(crossprod(tX)) %*% crossprod(tX, Y)
  curr.sigma <- as.double(crossprod(Y - tX %*% curr.beta)) / (tt * n - k)
  curr.gamma <- matrix(0, n, n)
  curr.rho <- 0
  curr.AI <- as.matrix(solve(Matrix::.sparseDiagonal(n) - curr.rho * curr.w))

  ### Gibbs sampling
  curr.A <- Matrix::.sparseDiagonal(n) - curr.rho * curr.w
  curr.logdet <- log(Matrix::det(curr.A))
  for (iter in 1:niter) {
    if (VERBOSE) {
      cat(
        "iter:", iter,
        "W:", sum(curr.w > 0),
        "min_k", min(rowSums(curr.w > 0)),
        "sigma:", round(curr.sigma, 2),
        "rho:", curr.rho, "\n"
      )
    }
    curr.A <- Matrix::.sparseDiagonal(n) - curr.rho * curr.w
    Ay <- matrix(curr.A %*% tY, n * tt, 1)

    # draw beta
    # e1 = try({
    V <- solve(beta_prior_var_inv + 1 / curr.sigma * crossprod(tX))
    b <- V %*% (beta_prior_var_inv %*% priors$beta_prior_mean + 1 / curr.sigma * crossprod(tX, Ay))
    # curr.beta = mvrnorm(1,b,V)
    curr.beta <- b + t(chol(V)) %*% stats::rnorm(k)
    curr.xb <- tX %*% curr.beta
    curr.txb <- matrix(curr.xb, n, tt)

    # draw sigma
    curr.ESS <- crossprod(Ay - curr.xb)
    curr.sigma <- 1 / stats::rgamma(1, priors$sigma_a + (tt * n) / 2, priors$sigma_b + as.double(curr.ESS) / 2)

    ## Griddy-Gibbs step for rho
    if (GRIDDY_GIBBS) {
      logdets <- lndetPaceBarry(curr.w, length.out = priors$griddy_n,
                                rmin = priors$rmin, rmax = priors$rmax)[-priors$griddy_n, ]
      wY <- curr.w %*% tY
      # ess.grid1 = sapply(logdets[,2], function(x) sum(dnorm(as.matrix(tY - x*wY),curr.txb,sqrt(curr.sigma),log = tt))  )
      ess.grid <- sapply(logdets[, 2], function(x) -sum(((tY - x * wY) - curr.txb)^2) / (2 * curr.sigma))
      den <- tt * logdets[, 1] + ess.grid + log(beta_prob(logdets[, 2], priors$rho_pr))
      log_cond_post_rho <- den
      log_cond_post_rho <- log_cond_post_rho - max(log_cond_post_rho)
      cond_post_rho <- exp(log_cond_post_rho)
      z <- cumsum(cond_post_rho) / sum(cond_post_rho)
      rnd <- stats::runif(1) #* sum(z)
      ind <- min(which(rnd <= z))
      if (is.integer(ind) && ind <= length(logdets[, 2])) {
        curr.rho <- logdets[ind, 2]
        curr.A <- Matrix::.sparseDiagonal(n) - curr.rho * curr.w
        curr.AI <- as.matrix(solve(curr.A))
        curr.logdet <- log(Matrix::det(curr.A))
      }
    } else {
      # draw p(rho | .) using MH-step
      accept <- 0
      while (accept != 1) {
        prop.rho <- stats::rnorm(1, curr.rho, rho_scale)
        if (prop.rho < priors$rmax && prop.rho > priors$rmin) {
          accept <- 1
        }
      }
      prop.A <- Matrix::.sparseDiagonal(n) - prop.rho * curr.w
      prop.logdet <- suppressWarnings(log(det(prop.A)))

      if (iter == 1) {
        curr.logdet <- log(det(curr.A))
      }
      post_curr <- tt * curr.logdet +
        sum(stats::dnorm(as.matrix(curr.A %*% tY), curr.txb, sqrt(curr.sigma), log = T)) +
        log(beta_prob(curr.rho, priors$rho_pr))
      post_prop <- tt * prop.logdet +
        sum(stats::dnorm(as.matrix(prop.A %*% tY), curr.txb, sqrt(curr.sigma), log = T)) +
        log(beta_prob(prop.rho, priors$rho_pr))

      acc_prob <- post_prop - post_curr
      if (is.nan(acc_prob) == FALSE) {
        if ((acc_prob) > log(stats::runif(1, 0, 1))) {
          curr.rho <- prop.rho
          curr.A <- prop.A
          curr.AI <- as.matrix(solve(prop.A))
          curr.logdet <- prop.logdet
          rho_accept <- rho_accept + 1
        }
      }
      if (iter < (ndiscard / 2)) {
        # rho tuning
        if ((rho_accept / iter) > 0.3) {
          rho_scale <- 1.1 * rho_scale
        }
        if ((rho_accept / iter) < 0.1) {
          rho_scale <- 0.9 * rho_scale
        }
      }
    }

    # Gibbs step for W - element-wise
    # curr.txb = matrix(curr.xb,n,tt)
    if (SYMMETRIC) {
      ii_samples <- sample(2:n, n - 1, replace = F)
    } else {
      ii_samples <- sample(1:n, n, replace = F)
    }
    for (ii in ii_samples) {
      if (SYMMETRIC) {
        jj_samples <- sample(c(1:(ii - 1)), ii - 1, replace = F)
      } else {
        jj_samples <- sample(1:n, n, replace = F)
      }
      for (jj in jj_samples) {
        if (priors$W_prior[ii, jj] == 0) {
          curr.W[ii, jj] <- 0
        } else if (priors$W_prior[ii, jj] == 1) {
          curr.W[ii, jj] <- 1
        } else {
          if (SYMMETRIC) {
            ch_elmnt <- c(ii, jj)
          } else {
            ch_elmnt <- ii
          }
          W0 <- W1 <- curr.W
          was1 <- (curr.W[ii, jj] == 1)
          if (was1) {
            W0[ii, jj] <- 0
            if (SYMMETRIC) {
              WW0 <- (W0 + t(W0))
            } else {
              WW0 <- W0
            }
            w0 <- w1 <- curr.w
            if (ROW_STANDARDIZED) {
              w0[ch_elmnt, ] <- WW0[ch_elmnt, ] / rowSums(WW0[ch_elmnt, , drop = F])
            } else {
              w0[ch_elmnt, ] <- WW0[ch_elmnt, ]
            }
            w0[is.na(w0)] <- 0
            A0 <- diag(n) - curr.rho * w0
            A1 <- curr.A
            diff0 <- A0[ch_elmnt, , drop = F] - curr.A[ch_elmnt, , drop = F]
            res0 <- update_ldetAI(ch_elmnt, diff0, curr.AI, curr.logdet)
            logdet0 <- res0$logdet
            logdet1 <- curr.logdet
          } else {
            W1[ii, jj] <- 1
            if (SYMMETRIC) {
              WW1 <- (W1 + t(W1))
            } else {
              WW1 <- W1
            }
            w0 <- w1 <- curr.w
            if (ROW_STANDARDIZED) {
              w1[ch_elmnt, ] <- WW1[ch_elmnt, ] / rowSums(WW1[ch_elmnt, , drop = F])
            } else {
              w1[ch_elmnt, ] <- WW1[ch_elmnt, ]
            }
            w1[is.na(w1)] <- 0
            A1 <- diag(n) - curr.rho * w1
            A0 <- curr.A
            diff1 <- A1[ch_elmnt, , drop = F] - curr.A[ch_elmnt, , drop = F]
            logdet0 <- curr.logdet
            res1 <- update_ldetAI(ch_elmnt, diff1, curr.AI, curr.logdet)
            logdet1 <- res1$logdet
          }

          curr.W_prior <- priors$W_prior
          # # rejection prior
          if (priors$rjct_pr) {
            if (SYMMETRIC) {
              W_reject1 <- rowSums(w1[c(ii, jj), ] > 0) > priors$max_k
            } else {
              W_reject1 <- sum(W1[ii, ]) > priors$max_k
            }
            if (sum(W_reject1) > 0) {
              curr.W_prior[ii, jj] <- 0
            }
            if (SYMMETRIC) {
              W_reject0 <- rowSums(w0[c(ii, jj), ] > 0) < priors$min_k
            } else {
              W_reject0 <- sum(W0[ii, ]) < priors$min_k
            }
            if (sum(W_reject0) > 0) {
              curr.W_prior[ii, jj] <- 1
            }
          }
          if (priors$bb_pr) {
            if (SYMMETRIC) {
              neighb0 <- sum((W0 + t(W0))[ii, ])
            } else {
              neighb0 <- sum(W0[ii, ])
            }
            # bbprior0 = bbinompdf(neighb0,n-1,bbinom_a,bbinom_b) * (1 - curr.W_prior[ii,jj])
            bbprior0 <- bbinompdf(neighb0, n - 1,priors$bbinom_a, priors$bbinom_b, priors$min_k, priors$max_k) *
              (1 - curr.W_prior[ii, jj])
            # if (neighb0 == 0) {bbprior0 = 0}
            if (SYMMETRIC) {
              neighb1 <- sum((W1 + t(W1))[ii, ])
            } else {
              neighb1 <- sum(W1[ii, ])
            }
            # bbprior1 = bbinompdf(neighb1,n-1,bbinom_a,bbinom_b) * curr.W_prior[ii,jj]
            bbprior1 <- bbinompdf(neighb1, n - 1, priors$bbinom_a, priors$bbinom_b, priors$min_k, priors$max_k) *
              curr.W_prior[ii, jj]
            bbprior_ <- bbprior1 / (bbprior1 + bbprior0)
          } else {
            bbprior_ <- curr.W_prior[ii, jj]
          }

          err1 <- sum((A1[ch_elmnt, ] %*% tY - curr.txb[ch_elmnt, ])^2)
          err0 <- sum((A0[ch_elmnt, ] %*% tY - curr.txb[ch_elmnt, ])^2)
          adj <- min(err0, err1)
          err1 <- err1 - adj
          err0 <- err0 - adj

          # change 23.02.2022
          #p1 =   bbprior_ * exp(logdet1*tt) * dnorm(err1,0,sqrt(curr.sigma))
          #p0 = (1- bbprior_) * exp(logdet0*tt) * dnorm(err0,0,sqrt(curr.sigma))
          p1 <- bbprior_ * exp(logdet1 * tt) * exp(-err1 / (curr.sigma))
          p0 <- (1 - bbprior_) * exp(logdet0 * tt) * exp(-err0 / (curr.sigma))

          prob.delta <- p1 / (p1 + p0)
          if (is.na(prob.delta)) {
            prob.delta <- 0
          }
          rnd_draw <- stats::runif(1)
          if (rnd_draw <= prob.delta) {
            curr.W[ii, jj] <- 1
            if (!was1) {
              curr.logdet <- logdet1
              curr.A <- A1
              curr.AI <- res1$AI
              curr.w <- w1
            }
          } else {
            curr.W[ii, jj] <- 0
            if (was1) {
              curr.logdet <- logdet0
              curr.A <- A0
              curr.AI <- res0$AI
              curr.w <- w0
            }
          }
        }
        curr.gamma[ii, jj] <- curr.W[ii, jj]
      }
    }
    if (ROW_STANDARDIZED) {
      if (SYMMETRIC) {
        curr.w <- (curr.W + t(curr.W)) / rowSums(curr.W + t(curr.W))
      } else {
        curr.w <- curr.W / rowSums(curr.W)
      }
      if (any(is.na(curr.w))) {
        curr.w[is.na(curr.w)] <- 0
      }
    } else {
      if (SYMMETRIC) {
        curr.w <- curr.W + t(curr.W)
      } else {
        curr.w <- curr.W
      }
    }
    curr.WX = as.matrix(kronecker(Matrix::.sparseDiagonal(tt),curr.w) %*% X)
    tX = cbind(X,curr.WX,Z)

    # we are past the burn-in, save the draws
    if (iter > ndiscard) {
      s <- iter - ndiscard
      postb[, s] <- as.matrix(curr.beta)
      posts[s] <- curr.sigma
      postr[s] <- curr.rho
      postw[, , s] <- curr.w

      post.direct[, s] <- sum(diag(curr.AI)) / n * curr.beta[ind_baseX]
      post.total[, s] <- sum(curr.AI) / n * curr.beta[ind_baseX]
      # if we have WX
      if (smallk > 0) {
        post.direct[ind_lagFX,s] = post.direct[ind_lagFX,s] +
          sum(diag(curr.AI))/n * curr.beta[ind_WX]
        post.total[ind_lagFX,s] = post.total[ind_lagFX,s] +
          sum(curr.AI)/n * curr.beta[ind_WX]
      }
      post.indirect[, s] <- post.total[, s] - post.direct[, s]
    }
  }

  ret = list(Y = Y, X = X,
    postb = postb, posts = posts, postr = postr, postw = postw,
    post.direct = post.direct, post.indirect = post.indirect, post.total = post.total,
    priors = priors,
    param = list(niter = niter, nretain = nretain,
                 VERBOSE = VERBOSE, SYMMETRIC = SYMMETRIC,
                 GRIDDY_GIBBS = GRIDDY_GIBBS, ROW_STANDARDIZED = ROW_STANDARDIZED)
  )
  class(ret) = "estimateW"
  return(ret)
}



