#' A sampler for estimating the W matrix in a SAR type model
#'
#' The model takes the form \eqn{Y = \rho f(\Omega)Y + X \beta_1 +  \epsilon}, with \eqn{\epsilon \sim N(0,\sigma^2)}
#'
#' @param Y An \eqn{tt n x 1} matrix of dependent variables
#' @param tt Number of time observations
#' @param X An \eqn{tt n x q_x} matrix of independent variables
#' @param niter Total number of iterations
#' @param nretain Number of iterations to retain (must be smaller than niter)
#' @param W_prior List of priors for estimating \eqn{W}, generated by \code{\link{W_priors}}
#' @param rho_prior List of priors for estimating \eqn{\rho}, generated by \code{\link{rho_priors}}
#' @param beta_prior List of priors for the slope coefficients \eqn{\beta}, generated by \code{\link{beta_priors}}
#' @param sigma_prior List of priors for the error variance \eqn{\sigma^2}, generated by \code{\link{sigma_priors}}
#'
#' @return List with posterior samples for \eqn{\rho}, \eqn{\beta}, \eqn{\sigma^2}, \eqn{w}, and direct, indirect, and total effects.
#' @export sarw
#'
#' @examples
#' n = 20; tt = 10
#' dgp_dat = sim_dgp(n =n, tt = tt, rho = .5, beta3 = c(.5,1), sigma2 = .5)
#' res = sarw(Y = dgp_dat$Y,tt = tt,X = dgp_dat$Z,niter = 20,nretain = 10)
sarw <- function(Y, tt, X, niter = 1000, nretain = 250,
                 W_prior = W_priors(n = nrow(Y)/tt),rho_prior = rho_priors(),
                 beta_prior = beta_priors(k = ncol(X)),sigma_prior = sigma_priors()) {
  ret = sdmw(Y = Y, tt =tt, X = matrix(0,nrow(Y),0),Z = X, niter = niter, nretain = nretain,
             W_prior = W_prior,rho_prior = rho_prior,
             beta_prior = beta_prior,sigma_prior = sigma_prior)
  ret$X = ret$Z; ret[["Z"]] = NULL
  ret$model_type = "sar"
  return(ret)
}


#' A sampler for estimating the W matrix in a SDM type model
#'
#' The model takes the form \eqn{Y = \rho f(\Omega)Y + X \beta_1 + f(\Omega)X \beta_2 + Z \beta_3 +  \epsilon}, with \eqn{\epsilon \sim N(0,\sigma^2)}
#'
#' @param Y An \eqn{tt n x 1} matrix of dependent variables
#' @param tt Number of time observations
#' @param X An \eqn{tt n x q_x} matrix of independent variables
#' @param Z An \eqn{tt n x q_k} matrix of independent variables
#' @param niter Total number of iterations
#' @param nretain Number of iterations to retain (must be smaller than niter)
#' @param W_prior List of priors for estimating \eqn{W}, generated by \code{\link{W_priors}}
#' @param rho_prior List of priors for estimating \eqn{\rho}, generated by \code{\link{rho_priors}}
#' @param beta_prior List of priors for the slope coefficients \eqn{\beta}, generated by \code{\link{beta_priors}}
#' @param sigma_prior List of priors for the error variance \eqn{\sigma^2}, generated by \code{\link{sigma_priors}}
#'
#' @return List with posterior samples for \eqn{\rho}, \eqn{\beta}, \eqn{\sigma^2}, \eqn{w}, and direct, indirect, and total effects.
#' @export sdmw
#'
#' @examples
#' n = 20; tt = 10
#' dgp_dat = sim_dgp(n =n, tt = tt, rho = .5, beta1 = c(.5,1),beta2 = c(-1,.5),
#'             beta3 = c(1.5), sigma2 = .5)
#' res = sdmw(Y = dgp_dat$Y,tt = tt,X = dgp_dat$X,Z = dgp_dat$Z,niter = 20,nretain = 10)
sdmw <- function(Y, tt, X = matrix(0,nrow(Y),0),Z = matrix(1,nrow(Y),1), niter = 1000, nretain = 250,
                  W_prior = W_priors(n = nrow(Y)/tt),rho_prior = rho_priors(),
                  beta_prior = beta_priors(k = ncol(X)*2 + ncol(Z)),sigma_prior = sigma_priors()) {
  if (ncol(X) == 0 && ncol(Z) == 0) {stop("Error: At least either X or Z matrix have to be provided.")}
  origX = X

  smallk = ncol(X)
  if (smallk>0 && is.null(colnames(X))) {
    colnames(X) = paste0("X",1:smallk)
  }
  k_dum = ncol(Z)
  if (k_dum>0 && is.null(colnames(Z))) {
    colnames(Z) = paste0("Z",1:k_dum)
  }
  if (smallk>0) {varnames = c(colnames(X), paste0("W_",colnames(X)))} else {varnames = c()}
  if (k_dum > 0) varnames = c(varnames,colnames(Z))

  if (!W_prior$row_standardized_prior && rho_prior$use_griddy_gibbs) {
    stop("No support for rho prior Griddy Gibbs without row-standardization prior for W!")
  }

  ndiscard <- niter - nretain
  k <- smallk*2 + k_dum
  n <- nrow(X) / tt

  # map variable positions for spatial effects
  ind_baseX = ind_WX = ind_lagFX = c()
  if (smallk > 0) {
    ind_baseX = c(1:smallk)
    # the columns of XX that are spatially lagged
    ind_WX = c(1:smallk) + smallk
    # the spatial FX corresponding to these
    ind_lagFX = 1:smallk
  }
  if (k_dum > 0) {ind_baseX = c(ind_baseX,(2*smallk + 1):k)}

  rho_scale <- rho_prior$init_rho_scale
  rho_accept <- 0

  # save the posterior draws here
  postb <- matrix(0, k, nretain)
  rownames(postb) <- varnames
  posts <- matrix(0, 1, nretain); rownames(posts) = "sigma"
  postr <- matrix(0, 1, nretain); rownames(postr) = "rho"
  postw <- array(0, c(n, n, nretain))
  postwprob <- array(0, c(n, n, nretain))

  post.direct <- matrix(0, smallk + k_dum, nretain)
  post.indirect <- matrix(0, smallk + k_dum, nretain)
  post.total <- matrix(0, smallk + k_dum, nretain)
  rownames(post.direct) <- rownames(post.indirect) <- rownames(post.total) <- varnames[ind_baseX]

  # initilize wdraws
  curr.rho <- rho_prior$init.rho
  curr.wdraws = init_sampler_W(W_prior,rho = curr.rho)

  curr.WX = as.matrix(kronecker(Matrix::.sparseDiagonal(tt),curr.wdraws$curr.w) %*% X)
  tX = cbind(X,curr.WX,Z)
  tY <- matrix(Y, n, tt)
  curr.txb1 = curr.txb2 = matrix(0,n,tt)
  tAy <- matrix(0, n, tt)
  curr.beta <- solve(crossprod(tX)) %*% crossprod(tX, Y)
  curr.sigma <- as.double(crossprod(Y - tX %*% curr.beta)) / (tt * n - k)
  curr.AI <- curr.wdraws$curr.AI
  curr.A <- curr.wdraws$curr.A
  curr.logdet <- curr.wdraws$curr.logdets

  ### Gibbs sampling
  pb <- utils::txtProgressBar(min = 0, max = niter, style = 3)
  for (iter in 1:niter) {
    Ay <- matrix(curr.wdraws$curr.A %*% tY, n * tt, 1)

    # draw beta
    # e1 = try({
    V <- solve(beta_prior$beta_var_prior_inv + 1 / curr.sigma * crossprod(tX))
    b <- V %*% (beta_prior$beta_var_prior_inv %*% beta_prior$beta_mean_prior + 1 / curr.sigma * crossprod(tX, Ay))
    # curr.beta = mvrnorm(1,b,V)
    curr.beta <- b + t(chol(V)) %*% stats::rnorm(k)
    curr.xb <- tX %*% curr.beta
    curr.txb <- matrix(curr.xb, n, tt)
    if (smallk > 0) {
      curr.txb1 = matrix(tX[,-ind_WX] %*% curr.beta[-ind_WX],n,tt)
      curr.txb2 = matrix(X %*% curr.beta[ind_WX],n,tt)
    } else {
      curr.txb1 = matrix(curr.xb,n,tt)
    }

    # draw sigma
    curr.ESS <- crossprod(Ay - curr.xb)
    curr.sigma <- 1 / stats::rgamma(1, sigma_prior$sigma_rate_prior + (tt * n) / 2, sigma_prior$sigma_shape_prior + as.double(curr.ESS) / 2)

    ## Griddy-Gibbs step for rho
    if (rho_prior$use_griddy_gibbs) {
      logdets <- lndetPaceBarry(curr.wdraws$curr.w, length.out = rho_prior$griddy_n,
                                rmin = rho_prior$rho_min, rmax = rho_prior$rho_max)[-rho_prior$griddy_n, ]
      wY <- curr.wdraws$curr.w %*% tY
      # ess.grid1 = sapply(logdets[,2], function(x) sum(dnorm(as.matrix(tY - x*wY),curr.txb,sqrt(curr.sigma),log = tt))  )
      ess.grid <- sapply(logdets[, 2], function(x) -sum(((tY - x * wY) - curr.txb)^2) / (2 * curr.sigma))
      den <- tt * logdets[, 1] + ess.grid + log(betapdf(logdets[, 2], rho_prior$rho_a_prior, rho_prior$rho_b_prior, rho_prior$rho_min, rho_prior$rho_max))
      log_cond_post_rho <- den
      log_cond_post_rho <- log_cond_post_rho - max(log_cond_post_rho)
      cond_post_rho <- exp(log_cond_post_rho)
      z <- cumsum(cond_post_rho) / sum(cond_post_rho)
      rnd <- stats::runif(1) #* sum(z)
      ind <- min(which(rnd <= z))
      if (is.integer(ind) && ind <= length(logdets[, 2])) {
        curr.rho <- logdets[ind, 2]
        curr.wdraws$curr.A <- Matrix::.sparseDiagonal(n) - curr.rho * curr.wdraws$curr.w
        curr.wdraws$curr.AI <- as.matrix(solve(curr.wdraws$curr.A))
        curr.wdraws$curr.logdet <- log(Matrix::det(curr.wdraws$curr.A))
      }
    } else {
      # draw p(rho | .) using MH-step
      accept <- 0
      while (accept != 1) {
        prop.rho <- stats::rnorm(1, curr.rho, rho_scale)
        if (prop.rho < rho_prior$rho_max && prop.rho > rho_prior$rho_max) {
          accept <- 1
        }
      }
      prop.A <- Matrix::.sparseDiagonal(n) - prop.rho * curr.wdraws$curr.w
      prop.logdet <- suppressWarnings(log(det(prop.A)))

      post_curr <- tt * curr.wdraws$curr.logdet +
        sum(stats::dnorm(as.matrix(curr.wdraws$curr.A %*% tY), curr.txb, sqrt(curr.sigma), log = T)) +
        log(betapdf(curr.rho, rho_prior$rho_a_prior, rho_prior$rho_b_prior, rho_prior$rho_min, rho_prior$rho_max))
      post_prop <- tt * prop.logdet +
        sum(stats::dnorm(as.matrix(prop.A %*% tY), curr.txb, sqrt(curr.sigma), log = T)) +
        log(betapdf(prop.rho, rho_prior$rho_a_prior, rho_prior$rho_b_prior, rho_prior$rho_min, rho_prior$rho_max))

      acc_prob <- post_prop - post_curr
      if (is.nan(acc_prob) == FALSE) {
        if ((acc_prob) > log(stats::runif(1, 0, 1))) {
          curr.rho <- prop.rho
          curr.wdraws$curr.A <- prop.A
          curr.wdraws$curr.AI <- as.matrix(solve(prop.A))
          curr.wdraws$curr.logdet <- prop.logdet
          rho_accept <- rho_accept + 1
        }
      }
      if (iter < (ndiscard / 2)) {
        # rho tuning
        if ((rho_accept / iter) > 0.3) {
          rho_scale <- 1.1 * rho_scale
        }
        if ((rho_accept / iter) < 0.1) {
          rho_scale <- 0.9 * rho_scale
        }
      }
    }

    # Gibbs step for W - element-wise
    # curr.txb = matrix(curr.xb,n,tt)
    curr.wdraws = sample_W(tY = tY,curr.txb1 = curr.txb1,
                           curr.txb2 = curr.txb2,
                           curr.sigma = curr.sigma,
                           W_prior = W_prior,wdraws = curr.wdraws,curr.rho = curr.rho)

    curr.WX = as.matrix(kronecker(Matrix::.sparseDiagonal(tt),curr.wdraws$curr.w) %*% X)
    tX = cbind(X,curr.WX,Z)

    # we are past the burn-in, save the draws
    if (iter > ndiscard) {
      s <- iter - ndiscard
      postb[, s] <- as.matrix(curr.beta)
      posts[s] <- curr.sigma
      postr[s] <- curr.rho
      postw[, , s] <- curr.wdraws$curr.w

      post.direct[, s] <- sum(diag(curr.wdraws$curr.AI)) / n * curr.beta[ind_baseX]
      post.total[, s] <- sum(curr.wdraws$curr.AI) / n * curr.beta[ind_baseX]
      # if we have WX
      if (smallk > 0) {
        post.direct[ind_lagFX,s] = post.direct[ind_lagFX,s] +
          sum(diag(curr.wdraws$curr.AI))/n * curr.beta[ind_WX]
        post.total[ind_lagFX,s] = post.total[ind_lagFX,s] +
          sum(curr.wdraws$curr.AI)/n * curr.beta[ind_WX]
      }
      post.indirect[, s] <- post.total[, s] - post.direct[, s]
    }
    utils::setTxtProgressBar(pb,iter)
  }
  close(pb)

  ret = list(Y = Y, X = X,Z = Z,
    postb = postb, posts = posts, postr = postr, postw = postw,
    post.direct = post.direct, post.indirect = post.indirect, post.total = post.total,
    W_prior = W_prior,rho_prior = rho_prior,
    beta_prior = beta_prior,sigma_prior = sigma_prior,
    param = list(niter = niter, nretain = nretain)
  )
  class(ret) = "estimateW"
  return(ret)
}



